---
title: "Tarea_Mineria_2"
author: "Laura Piñeros"
date: "4/3/2022"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#caragmos librerias
#Grupo de librerias 1
library(readxl)#libreria para importar 
library(knitr)#libreria para las tablas 
#Grupo de librerias 1
library(pastecs)#para estadistico multivariantes
library(ggplot2)
library(corrplot)#para visualizar matrices de correlacion 
#Grupo de librerias especificas para el modulo 
library(factoextra)
library(FactoMineR)#para realizar analisis multivariante(mineria de datos)
library(lattice)
library(rmarkdown)
library(ggrepel)
library(cluster)
library(heatmaply)#representar mapas de calor (para distancias)
library(NbClust)#determinar numero optimo de cluster que se encuentra en nuestro conjunto de datos 
library(seriation)
```

El fichero Provincias.xlsx contiene informaciòn socio-econòmica de las provincias españolas.  

**Ejercicio 1 (0.5).** Calcular la matriz de correlaciones, y su representación gráfica ¿Cuáles son las variables más correlacionadas de forma inversa?

```{r}
#getwd()
Provincias <- read_excel("~/Escritorio/UCM/Mineria y modelizacion_2/Evaluacion/Provincias.xlsx" )
datos <- as.data.frame(Provincias)
#Estadisticos básicos de variables opción summary() 
summary(datos)
```
```{r}
rownames(datos)<-datos[,1]
datos_n<-datos[,-c(1)]
```

Una vez hemos sacado lo datos de tipo categóricos, saquemos la matriz de correlaciones, y veamos su representación gŕafica 

```{r}
R <- cor(datos_n, method="pearson")#metodo pearson para encontrar las correlaciones entre variable
matriz_cor <- as.data.frame(R)
corrplot(R,type="upper", order = "hclust",tl.col = "black", tl.cex = 0.6,tl.srt = 90)
#tl.col <- color de las etiquetas 
#tl.cex <- tamaño de letra 
#tl.srt <- espaciado entre etieutas y recuadros entre si. 
#Ordenación de las hojas en un diagrama hclust
# tipo de cuadricula superior 
#metodo <- mide que tan corellacionadas estan las variables por el método de pearson 
```
Notemos que: 

- Si en una provincia hay mayor cantidad de defunciones entonces hay un menor Tasa de actividad. A medida que aumenta la mortalidad, disminuye la Tasa de Actividad, lo que significa que tienen una correlación de tipo inversa. Así mismo sucede con las variables Mortalidad y Natalidad. 

- El grupo de varaibles asociados a la industria junto con la Tasa de ocupados, los censos y el PIB, marcan una relación altamente positiva. 

- El CANE , Censo agrario no aporta mucho en relación con las demas variables, aunq ue faltaría estudiar el caso con el censo 2011 de viviendas secundarias.

A continuación presentamos los gŕaficos, asociados a los comportamientos de las variables. 

```{r}
xyplot(TasaActividad ~ Mortalidad, data =datos,  main="Tasa de Actividad y Mortalidad ", type=c("p","r"),pch=19)
xyplot(Natalidad ~ Mortalidad, data =datos,  main="Natalidad y Mortalidad ", type=c("p","r"),pch=19, col='red')
```

**Ejercicio 2 (0.5).**  Realizar un análisis de componentes principales sobre la matriz de correlaciones, calculando 7 componentes. Estudiar los valores de los autovalores obtenidos y las gráficas que los resumen. ¿Cuál es el número adecuado de componentes?

```{r}
#calcular el analisis de componentes ´principales 
fit7 <- PCA(datos_n,scale.unit = TRUE,ncp = 7,graph = FALSE)
#graph tambien puede ser TTRUE en el caso en el que quiera mostrar los graficos correspondientes 
#datos_n <- contiene todas las variables numéricas 
#Variable estandar es aquella a la que se le ha restado la media y se ha dividio por su desviación tipica
#scale.unit = TRUE <- hallas los autovalores de la matriz de correlaciones. Es decir la matriz a diagonalizar es la matriz de correlaciones entre las variables. 
#ncp: numero de componentes a retener en el resultado final
```

Veamos los autovalores de la matriz de correlaciones, y realicemos el análisis de las varianzas. 


```{r}
#Autovalores de la matriz R 
eig<-get_eigenvalue(fit7)
knitr::kable(eig, digits =2,caption = "Autovalores")
#Porcentaje de variabilidad acumulada 
fviz_eig(fit7,addlabels=TRUE)
```

Sabemos que con la matriz de correlación  de allí tomaremos los autovalores que contribuyen en el porcentaje de varianza acumulada para elegir las componentes principales que son la combinación lineal de los autovectores generados por dichos autovalores. 
Para este ejercicio estipula 7 componentes principales, pero bajo el análisis pueden ser 3 o 4, pues estaría explicada la variabilidad aproximadamente en un 90%. 

**Ejercicio 3.**  Hacer de nuevo el análisis sobre la matriz de correlaciones pero ahora indicando el número de componentes principales que hemos decidido retener(Que expliquen eproximadamente el 90%). Sobre este análisis contestar los siguientes apartados. 

```{r}
fit3 <- PCA(datos_n,scale.unit = TRUE,ncp = 3,graph = FALSE)
```

**a. (1)** Mostrar los coeficientes para obtener las componentes principales. ¿ Cuál es la expresión para calcular la primera Componente en función de las variables originales? 

```{r}
#coeficientes de las componentes principales 
knitr::kable(fit3$svd$V,digits =3,caption = "Autovectores")
```


Las componentes estarian determinadas de la siguiente manera,

- $$CP_1 = 0.294 Poblacion^{*} − 0,106 Mortalidad^{*} + .. . . + 0.292 TVF^{*} + 0.172 VS^{*}$$
- $$CP_2 = 0.002 Poblacion^{*} - 0.527 Mortalidad ^{*} + .. . .-0.002 TVF^{*} + 0.048 VS^{*}$$
- $$CP_3 = 0.050 Poblacion^{*} + 0.189 Mortalidad ^{*} + .. . .+0.100 TVF^{*} + 0.290 VS^{*}$$


**b. (0.5)** Mostar una tabla con las correlaciones de las Variables con las Componentes Principales. Para cada Componente indicar las variables con las que está más correlacionada

```{r}
var<-get_pca_var(fit3)
knitr::kable(var$cor, digits =2, caption = "Correlaciones de la CP con las variables")
``` 

**c. (1)**  Comentar los gráficos que representan las variables en los planos formados por las componentes, intentando explicar lo que representa cada componente.

```{r}
#Representación gráfica de las variables 
fviz_pca_var(fit3, axes = c(1, 2), col.var="cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel = TRUE)
```
Notemos que:

- Las varaibles Población,Num de empresas, el grupo asociado a industria, la cantidad de ocupados, el PIB y TVF tienen una correlación muy alta cercana al 1 con la Componente 1.
- Las variables TasaParo junto con natalidad tienen una correlación alta con la componente 2. Se destaca que la variable Población no esta correlacionada con con la Componente 2. 


```{r}
fviz_pca_var(fit3, axes = c(2,3), col.var="cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel = TRUE)
```
Notemos que:

- La variable CANE tiene una correlación alta con la componente 2. Se destaca que la variable Ocupados no esta correlacionada con la Componente 3. 

- Basandonos en este estudio podemos decir que en relación con la Componente 1 y las varaibles, estas tienen una correlación muy alta,y nos podría explicar muy bien los datos.  


**d. (0.25)** Mostrar la tabla y los gráficos que nos muestran la proporción de la varianza de cada variable que es explicado por cada componente. ¿Cuál de las variables es la que está peor explicada? 

```{r}
knitr::kable(var$cos2, digits =2,caption = "Cosenos al cuadrado(variabilidad de cada variable explicado por cada componente)")
```


```{r}
# RepresentaciÃ³n grÃ¡fica de los cosenos
corrplot(var$cos2,is.corr=FALSE,tl.cex=0.6,tl.col = "black", cl.ratio=1)
```

```{r}
fviz_cos2(fit3,choice="var",axes=1:3, tl.cex=0.6 )
```
Notemos que en el gráfico anterior se evidencia que VS(Viviendas secundarias) es la variable peor explicada respecto a las componentes. 

**e. (0.25)** Mostrar la tabla y los gráficos que nos muestran el porcentaje de la varianza de cada Componente que es debido a cada variable. ¿Que variables contribuyen más a cada Componente?

```{r}
knitr::kable(var$contrib,digits =2, caption = "Contribuciones")
```

```{r}
corrplot(var$contrib,is.corr=FALSE,tl.cex=0.6,tl.col = "black", cl.ratio=1 )
```

Contribucióń de las variables a las componentes. 

```{r}
fviz_contrib(fit3,choice="var",axes=1, tl.cex=0.6)
fviz_contrib(fit3,choice="var",axes=2, tl.cex=0.6)
fviz_contrib(fit3,choice="var",axes=3, tl.cex=0.6)
```

Notemos que:

- Respecto a la media, las variables que más contribuyen a la Componente 1 son, Ocupados, NUmEmpresas Poblacion y todo el grupo asociado a la Industria. 
- Respecto a la media, las variables que más contribuyen a la Componente 2 son, Mortalidad, Natalidad, TasaParo, IPC, TasaActividad. 
- Respecto a la media, las variables que más contribuyen a la Componente 3 son, CANE, TasaParo, TasaActividad, VS , Natalidad, IPC. 


**f. (1)** Sobre los gráficos que representan las observaciones en los nuevos ejes y el gráfico Biplot,teniendo en cuenta la posición de las provincias en el gráfico. Comentar las provincias que tienen una posición más destacada en cada componente, en positivo o negativo, ¿Qué significa esto en términos socioeconómicos para estas provincias? 

```{r}
fviz_pca_ind(fit3,axes = c(1, 2), col.ind = "cos2",col.cex=0.2, gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)
```
Para valores representativos del gŕafico anterior, 

- Se observa que la $$CP_1$$ Madrid y Barcelona tienen un valor alto por lo que  tienen una buena cantidad de Ocupados, de NUmEmpresas, de Poblacion y tienen un numero alto de todo tipo de Industrias, y de Construcción, mientras que Albacete , Soria, Palencia tienen valores negativos en dicha componente lo que indica que bajo numero de Ocupados y de Industria, etc. 

- En la $$CP_2$$, Melilla, Ceuta, Almería y Palmas presentan unos valores altos por lo que indica que tienen una Tasa alta de Mortalidad, Natalidad, Tasa de Paro, pero también hay un alto índice de inflación, mientras que Zamora, Lugo, Ourense, tienen valores negativos lo que indica bajas Tasas de Mortalidad , de natalidad, y hay un porcentaje mínimo de inflación. 

```{r}
fviz_pca_ind(fit3,axes = c(2, 3), col.ind = "cos2",col.cex=0.2, gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel = TRUE)
```

Para valores representativos del gŕafico anterior, 

- Se observa que la $$CP_3$$, Jaén, Valencia, ALicante, Ciudad Real, Badajoz tienen un alto número de explotaciones, altas tasas de Paro y de actividad, mientras que en Provincias como Balears, Melilla, Álava, no cuentan con un numero alto de explotaciones, etc. 

```{r}
fviz_pca_biplot(fit3, repel = TRUE, col.var = "#2E9FDF", col.cex=0.2,col.ind = "#696969") 
```

```{r}
fviz_pca_biplot(fit3, repel = TRUE,axes = c(2,3), col.cex=0.2, col.var= "#2E9FDF", col.ind = "#696969")
```

**g. (1)** Si tuviéramos que construir un índice que valore de forma conjunta el desarrollo económico de una provincia, como se podría construir utilizando una combinación lineal de todas las variables. ¿Cuál sería el valor de dicho índice en Madrid? ¿Cual sería su valor en Melilla?

```{r}
ind<-get_pca_ind(fit3)
knitr::kable(ind$coord,digits =3,caption = "Valores de las provincias en las Componentes")
```

$$ 16.778 \alpha -0.366\beta -0.849\gamma$$ para $$\alpha,\beta,\gamma =1 $$ el Índice económico de Madrid es $$5.18$$.
$$-2.218\alpha +4.782\beta -1.905\gamma$$ para $$\alpha,\beta,\gamma =1 $$ el índice económico de Melilla es $$0.21$$

**Ejercicio 4. (0.5)** Representar un mapa de calor de la matriz de datos, estandarizado y sin estandarizar para ver si se detectan inicialmente grupos de provincias.

Primero vamos a crear un conjunto de datos con las variables numéricas estandarizadas 

```{r}
data_ST<-scale(datos_n)
```

Veamos el mapa de calor para los datos estandarizados, 

```{r}
heatmaply(data_ST, seriate = "mean",row_dend_left = TRUE, plot_method = "plotly")
heatmaply(datos_n, seriate = "mean",row_dend_left = TRUE, plot_method = "plotly")
```


**Ejercicio 5.** Realizar un análisis Jerárquico de clusters para determinar si existen grupos de provincias con comportamiento similar.

Primero calcularemos las distancias con los valores sin estandarizar y mostremos las 6 primeras filas . 

```{r}
#Con valores sin estandarizar 
d <- dist(datos_n, method = "euclidean")
d6 <- as.matrix(d)[1:6,1:6]
knitr::kable(d6,digits = 2, caption = "Distancias")
```

Ahora, calculamos las distancias cpn los valores estandarizados. 


```{r}
d_st <- dist(data_ST, method = "euclidean") # distance matrix
d_st6<-as.matrix(d_st)[1:6, 1:6]
knitr::kable(d_st6, digits =2,caption = "Distancias")
```


Ahora veamos gŕaficamente la matriz de distancias, con los datos sin estandarizar 

```{r}
fviz_dist(d, show_labels = TRUE)
```

Con los datos estandarizados, 

```{r}
fviz_dist(d_st, show_labels = TRUE)
```

**a. (0.5)** A la vista del dendograma ¿Cuantos clusters recomendarías?. 

En ese orden, agrupamos las observaciones según el criterio de ward, y dibujamos el Dendograma correspondiente. 

Criterio Ward: Método de Ward o de la mínima varianza, este método, entre todas las uniones de cluster posibles en cada nivel, selecciona aquella unión que minimiza la variabilidad interna de los cluster resultantes.

```{r}
#método para medir distancias entre clusteres
#para datos sin estandarizar 
res.hc <- hclust(d, method="ward.D2")
fviz_dend(res.hc, cex = 0.5)
```
Realizamos el cluster jerárquico con las distancias entre los datos estandarizados. 

```{r}
res.hc_st <- hclust(d_st, method="ward.D2")
fviz_dend(res.hc_st, cex = 0.5)
```

A la vista recomendaria K=5 clusters.

**b. (0.5)** Representar los individuos agrupados según el número de clusters elegido.

```{r}
grp <- cutree(res.hc_st, k = 5)
knitr::kable(table(grp), caption = "Número de provincias por cluster")
```

```{r}
# Podemos ver las provincias del cluster 1-2-3-4-5
rownames(data_ST)[grp == 1]
rownames(data_ST)[grp == 2]
rownames(data_ST)[grp == 3]
rownames(data_ST)[grp == 4]
rownames(data_ST)[grp == 5]
```
```{r}
fviz_dend(res.hc_st, k = 3, # Cut in four groups
cex = 0.5, # label size
color_labels_by_k = TRUE, # color labels by groups
rect = TRUE) # Add rectangle around groups
```

Visualizamos los clusters

```{r}
#datos_ST <- matriz de datos estandatrizados 
fviz_cluster(list(data = data_ST, cluster = grp), ellipse.type = "convex", # Concentration ellipse
repel = TRUE, # Avoid label overplotting (slow)
show.clust.cent = FALSE, ggtheme = theme_minimal())
```

```{r}
#d_st <- matriz de distancias estandarizadas 
fviz_cluster(list(data = data_ST, cluster = grp),axes=c(3,4), ellipse.type = "convex", # Concentration ellipse
repel = TRUE, # Avoid label overplotting (slow)
show.clust.cent = FALSE, ggtheme = theme_minimal())
```


**c. (0.5)** ¿Qué número óptimo de clusters nos indican los criterios Silhoutte y de Elbow?

Determinción del número óptimo de clusters por le método Elbow

```{r}
fviz_nbclust(data_ST, kmeans, method = "wss") +
geom_vline(xintercept =3, linetype = 2)+
labs(subtitle = "Elbow method")
```
Silhouette method,

```{r}
fviz_nbclust(data_ST, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
```

Por el método Ebow decidimos tomar $$k=3$$ clusters

**d. ** Con el número de clústeres que nos indica Elbow en el apartado anterior, realizar un agrupamiento no jerárquico. 
 
 **i. (0.5)** Representar los clústeres formados en los planos de las Componentes principales. Relacionar la posición de cada clúster en el plano con lo que representa cada componente principal. 
 
 Vamos a realizar un análisis no jerárquico para $$k=3$$ clústeres. Fijemos la semilla. 

```{r}
RNGkind(sample.kind = "Rejection")
set.seed(1234)
km.res3 <- kmeans(data_ST, 3)
fviz_cluster(km.res3, data_ST)
```
```{r}
fviz_cluster(km.res3, data_ST,axes=c(3,4), ellipse.type = "convex", # Concentration ellipse
repel = TRUE, # Avoid label overplotting (slow)
show.clust.cent = FALSE, ggtheme = theme_minimal())
```

**ii. (0.5)** Evaluación de la calidad de los clústeres,

```{r}
sil <- silhouette(km.res3$cluster, dist(data_ST))
rownames(sil) <- rownames(datos)
head(sil[, 1:3])
```

```{r}
fviz_silhouette(sil)
```


**e. (1)**Explicar las provincias que forman cada uno de los clústeres y comentar cuales son las características socioeconómicas que las hacen pertenecer a dicho clúster. 

Primero veamos los grupo de provincias que forman cada uno de los clústres. 

```{r}
ordenado<-sort(km.res3$cluster)
knitr::kable(ordenado, digits =2, caption = "Provincia y cluster")
```


Veamos las características socioeconómicas de cada provincia, para ver que lo hace pertenecer a dicho clúster. 

```{r}
datos_n$grupo<- as.factor(km.res3$cluster)
ggplot(datos_n, aes(x=grupo, y=Poblacion, fill=grupo)) + geom_boxplot()

```

```{r}
g1<- ggplot(datos_n, aes(x=grupo, y=Mortalidad, fill=grupo)) + geom_boxplot()
g2<- ggplot(datos_n, aes(x=grupo, y=Natalidad, fill=grupo)) + geom_boxplot()
g3<- ggplot(datos_n, aes(x=grupo, y=IPC, fill=grupo)) + geom_boxplot()
g4<- ggplot(datos_n, aes(x=grupo, y=NumEmpresas, fill=grupo)) + geom_boxplot()
g5<- ggplot(datos_n, aes(x=grupo, y=Industria, fill=grupo)) + geom_boxplot()
g6<- ggplot(datos_n, aes(x=grupo, y=Construccion, fill=grupo)) + geom_boxplot()
g7<- ggplot(datos_n, aes(x=grupo, y=CTH, fill=grupo)) + geom_boxplot()
g8<- ggplot(datos_n, aes(x=grupo, y=Infor, fill=grupo)) + geom_boxplot()
gridExtra::grid.arrange(g1, g2, g3, g4, g5, g6, g7, g8, ncol=2, nrow=4)
```
```{r}
g9<- ggplot(datos_n, aes(x=grupo, y=AFS, fill=grupo)) + geom_boxplot()
g10<- ggplot(datos_n, aes(x=grupo, y=APT, fill=grupo)) + geom_boxplot()
g11<- ggplot(datos_n, aes(x=grupo, y=TasaActividad, fill=grupo)) + geom_boxplot()
g12<- ggplot(datos_n, aes(x=grupo, y=TasaParo, fill=grupo)) + geom_boxplot()
g13<- ggplot(datos_n, aes(x=grupo, y=Ocupados, fill=grupo)) + geom_boxplot()
g14<- ggplot(datos_n, aes(x=grupo, y=PIB, fill=grupo)) + geom_boxplot()
g15<- ggplot(datos_n, aes(x=grupo, y=CANE, fill=grupo)) + geom_boxplot()
g16<- ggplot(datos_n, aes(x=grupo, y=TVF, fill=grupo)) + geom_boxplot()
g17<- ggplot(datos_n, aes(x=grupo, y=VS, fill=grupo)) + geom_boxplot()
gridExtra::grid.arrange(g9, g10, g11, g12, g13, g14, g15, g16,g17 ,ncol=2, nrow=5)
```
Como lo creimos anterioremente, Madrid y Barcelona tienen caracteristicas asociadas al crecimiento industrial, al tipo de empresas en los sectores productivos, aunque no tiene altas tasas de Natalidad y Mortalidad. 

Por el contrario el grupo 2, muestra bajos inidices de crecimiento empresarial, pero si presenta altas tasas de mortalidad, inclusive una tasa de actividad Media. Así mismo, tampoco cuenta con un gran número de empresas , posiblemente, por que cuenta con una población muy baja. 

En el grupo 1 de provincias, podemos ver que, tampoco tiene un muy alto indice de crecimiento industrial, pero presenta índice de inflación mas bajo respecto a los otros grupos. 




